{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. (20 points) True or False.\n",
    "#(a) Random forest is not an ensemble learning technique. FALSE\n",
    "#(b) Support vector machine is an ensemble learning technique. TRUE\n",
    "#(c) If the classifier produce a 80% recall on test dataset (using default values for hyperparameters), there is no need to tune the classifier hyper-parameters.FALSE\n",
    "#(d) Random search and grid search always produce the same results. FALSE\n",
    "#(e) Increasing the value of max depth in tree-based models prevents overfitting. FALSE\n",
    "#(f) Scaling the input variables in tree-based models can speed up the hyper-parameter tuning process. FALSE\n",
    "#(g) Random search is preferred when the training dataset is big and the number of hyperparameter combinations is large. TRUE\n",
    "#(h) XGBoost always outperforms random forest. FALSE\n",
    "#(i) XGBoost is faster than regular gradient boosting algorithms because it trains the the base-learners in parallel. TRUE\n",
    "#(j) In order to avoid overfitting, it is recommended to tune the learning rate hyperparameter in random forest models. FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. (6 points) How does stacking work? Be specific.\n",
    "\n",
    "#Stacking in machine learning is an algorithm in which you take the results or predictions of multiple machine learning models and combine them\n",
    "#all together in order to create a meta model, a meta model then uses these results to more accuratly predict the data as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. (6 points) If you have trained three different models on the exact same training dataset, and they all achieve a 93% F1-score on\n",
    "#the exact same dataset. Is there any chance that you can combine these three models to get better results? If so, how? \n",
    "#If not, why? Be specific.\n",
    "\n",
    "#Yes even though the 93% is good, when we combine the 3 models together they have an opportunity to make these models as features which\n",
    "#could help to further accuratley predict on the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c14191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 If your AdaBoost model overfits the data (probably because the number of boosted trees is large)\n",
    "#what hyper-parameter you need to tune? Be specific.\n",
    "\n",
    "# The learning rate parameter would need to be lowered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57479ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Which of the following algorithm is NOT an ensemble learning algorithm?\n",
    "\n",
    "# A- Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfbc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 How does XGBoost with random forest as base learner work? Be specific.\n",
    "\n",
    "# Random forrest as a base learner works when it is implemented in XGboost with the num_parallel_trees parameter set greater than 1\n",
    "# This allows XGboost to operate similarly to random forrest by comparing multiple number of parralell trees rather than just 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86abfdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 How do we select the best hyper-parameter combination for a given model?\n",
    "\n",
    "#B- Performance on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8075f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8a If a data scientist wants to tune the number of trees based on the F1-score, how many trees would he select? Be specific.\n",
    "\n",
    "# He would choose 400 becasue that is where the F1 score is the highest and after this point there is no model improvemnt in both datasets\n",
    "\n",
    "#8b What is the reason there is big difference in the F1-score performance between the Train and Test datasets? Be specific.\n",
    "\n",
    "# The model is overfitting the data in favor of the train dataset which therefore creates worse results for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 What is the difference between homogeneous and heterogeneous ensembles? Be specific\n",
    "\n",
    "#with homegeneous, the same algorithms ared used for all the base learners within the different distributions in a dataset,\n",
    "#Whereas, heterogeneous ensembles are created using multiple different algorithms as base learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fe028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 Random forest is an example of\n",
    "\n",
    "# (d) (a) and (c) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7377b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 \n",
    "\n",
    "# This is a bad idea as when we set CV to 5 it splits the datset into 5,\n",
    "#which is not smart becasue there is only 4 fraudulent cases to predict from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecef274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12 a What is/are the hyper-parameters that may cause overfitting if we increase\n",
    "#their values while holding the values of the hyper-parameters constant? Be specific\n",
    "\n",
    "# learning rate, max depth,  and colsample bytree would be the hyper-parameters that would casue overfitting if we \n",
    "# kept the other parameters the same, the mentioned paramters if increased in signifgance would force the model to be more specific\n",
    "# and therefore more reliant on the training dataset\n",
    "\n",
    "#12b What is/are the hyper-parameters that prevents overfitting if we increase their values while holding the values\n",
    "#of the hyper-parameters constant? Be specific.\n",
    "\n",
    "# min child weight would limit how many times we could split the data which doesn't allow the model to be too specific within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fccde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13 In tree-based models, how does a data scientist optimize the number of trees? Be specific.\n",
    "\n",
    "# Tuning the parameter \"n_estimators\" would detremine the number of trees that would be considered in the model and thus limit overfitting and\n",
    "# maximize the optimization of the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14a What type of task the machine learning specialist is working on? Classification or regression? Be specific.\n",
    "\n",
    "# The scientist is working on a regression task as the objective \"reg:squarederror\" is only shown in regression tasks\n",
    "\n",
    "#14b Given the existing XGBoost hyper-parameters, what may be the reason that the XGBoost model is not performing as expected? Be specific.\n",
    "\n",
    "# Well to start, 2000 trees is a very easy way to over fit the data especially when you have a learning rate of 30, this would very quickly\n",
    "# make the model soley reliant on the train dataset rather than the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add37995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: XGBoost in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from XGBoost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from XGBoost) (1.5.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989410e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55773</td>\n",
       "      <td>55917</td>\n",
       "      <td>51389</td>\n",
       "      <td>48272</td>\n",
       "      <td>49478</td>\n",
       "      <td>51242</td>\n",
       "      <td>3028</td>\n",
       "      <td>3023</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>38662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>140</td>\n",
       "      <td>3230</td>\n",
       "      <td>3011</td>\n",
       "      <td>1964</td>\n",
       "      <td>1883</td>\n",
       "      <td>1538</td>\n",
       "      <td>3230</td>\n",
       "      <td>3011</td>\n",
       "      <td>1964</td>\n",
       "      <td>1883</td>\n",
       "      <td>1538</td>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59710</td>\n",
       "      <td>49986</td>\n",
       "      <td>104390</td>\n",
       "      <td>94856</td>\n",
       "      <td>86461</td>\n",
       "      <td>83650</td>\n",
       "      <td>1808</td>\n",
       "      <td>69563</td>\n",
       "      <td>2891</td>\n",
       "      <td>2689</td>\n",
       "      <td>3012</td>\n",
       "      <td>2771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280913</td>\n",
       "      <td>283222</td>\n",
       "      <td>273160</td>\n",
       "      <td>257689</td>\n",
       "      <td>193231</td>\n",
       "      <td>191143</td>\n",
       "      <td>11052</td>\n",
       "      <td>9563</td>\n",
       "      <td>15017</td>\n",
       "      <td>5374</td>\n",
       "      <td>5420</td>\n",
       "      <td>6021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1512</td>\n",
       "      <td>2458</td>\n",
       "      <td>664</td>\n",
       "      <td>1814</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>664</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0     400000    1          1         2   32      0      0      0      0   \n",
       "1     120000    2          2         2   30     -1     -1     -1     -1   \n",
       "2     270000    2          2         2   32      0      0      0      0   \n",
       "3     280000    2          2         1   27      0      0      0      0   \n",
       "4      30000    2          1         2   27      0      0     -1      0   \n",
       "\n",
       "   PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "0      0      0      55773      55917      51389      48272      49478   \n",
       "1     -1     -1        140       3230       3011       1964       1883   \n",
       "2      0      0      59710      49986     104390      94856      86461   \n",
       "3      0      0     280913     283222     273160     257689     193231   \n",
       "4      0     -2       1512       2458        664       1814          0   \n",
       "\n",
       "   BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0      51242      3028      3023      3000      3000      3000     38662   \n",
       "1       1538      3230      3011      1964      1883      1538      1911   \n",
       "2      83650      1808     69563      2891      2689      3012      2771   \n",
       "3     191143     11052      9563     15017      5374      5420      6021   \n",
       "4          0      1000       664      1500         0         0         0   \n",
       "\n",
       "   default payment next month  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd; pd.set_option('display.max_columns', 50)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import precision_recall_cutoff2 as prc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Defining the s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-445-wagner'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# Defining the file to be read from s3 bucket\n",
    "file_key = \"train(1).csv\"\n",
    "file_key2 = \"test(1).csv\"\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "bucket_object2 = bucket.Object(file_key2)\n",
    "\n",
    "file_object = bucket_object.get()\n",
    "file_object2 = bucket_object2.get()\n",
    "\n",
    "file_content_stream = file_object.get('Body')\n",
    "file_content_stream2 = file_object2.get('Body')\n",
    "\n",
    "#reading the csv file\n",
    "train = pd.read_csv(file_content_stream)\n",
    "test = pd.read_csv(file_content_stream2)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3cda55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>Total_Payment_Amount</th>\n",
       "      <th>Total_Payment</th>\n",
       "      <th>Total_Bill_Amount</th>\n",
       "      <th>Heredity1</th>\n",
       "      <th>Heredity2</th>\n",
       "      <th>DecisionTree1</th>\n",
       "      <th>DecisionTree2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>3625</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>501</td>\n",
       "      <td>902</td>\n",
       "      <td>544</td>\n",
       "      <td>398</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>544</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>-3</td>\n",
       "      <td>6073</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21617</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8557</td>\n",
       "      <td>8271</td>\n",
       "      <td>11127</td>\n",
       "      <td>10657</td>\n",
       "      <td>11178</td>\n",
       "      <td>11840</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1900</td>\n",
       "      <td>6900</td>\n",
       "      <td>7</td>\n",
       "      <td>61630</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20244</th>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16035</td>\n",
       "      <td>15493</td>\n",
       "      <td>16197</td>\n",
       "      <td>16669</td>\n",
       "      <td>16865</td>\n",
       "      <td>17199</td>\n",
       "      <td>0</td>\n",
       "      <td>1270</td>\n",
       "      <td>742</td>\n",
       "      <td>613</td>\n",
       "      <td>615</td>\n",
       "      <td>646</td>\n",
       "      <td>3886</td>\n",
       "      <td>4</td>\n",
       "      <td>98458</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19392</th>\n",
       "      <td>300000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18377</th>\n",
       "      <td>150000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1250</td>\n",
       "      <td>0</td>\n",
       "      <td>3871</td>\n",
       "      <td>6200</td>\n",
       "      <td>336</td>\n",
       "      <td>1250</td>\n",
       "      <td>0</td>\n",
       "      <td>3871</td>\n",
       "      <td>6200</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>11657</td>\n",
       "      <td>-12</td>\n",
       "      <td>11657</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "3092      500000    2          1         1   39     -2     -2     -1      2   \n",
       "21617      20000    1          2         2   47      1      2      2      2   \n",
       "20244      30000    1          1         2   24      2      2      0      0   \n",
       "19392     300000    1          1         2   29      1     -2     -2     -2   \n",
       "18377     150000    2          3         1   72     -2     -2     -2     -2   \n",
       "\n",
       "       PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "3092       2     -2       3625          0        501        501        902   \n",
       "21617      0      0       8557       8271      11127      10657      11178   \n",
       "20244      0      0      16035      15493      16197      16669      16865   \n",
       "19392     -2     -2          0          0          0          0          0   \n",
       "18377     -2     -2          0       1250          0       3871       6200   \n",
       "\n",
       "       BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "3092         544       398       501         0       544       544         0   \n",
       "21617      11840         0      3000         0      1000      1000      1900   \n",
       "20244      17199         0      1270       742       613       615       646   \n",
       "19392          0         0         0         0         0         0         0   \n",
       "18377        336      1250         0      3871      6200       336         0   \n",
       "\n",
       "       Total_Payment_Amount  Total_Payment  Total_Bill_Amount  Heredity1  \\\n",
       "3092                   1987             -3               6073          4   \n",
       "21617                  6900              7              61630          2   \n",
       "20244                  3886              4              98458          4   \n",
       "19392                     0             -9                  0         -2   \n",
       "18377                 11657            -12              11657          4   \n",
       "\n",
       "       Heredity2  DecisionTree1  DecisionTree2  \n",
       "3092           2              1              0  \n",
       "21617          2              0              0  \n",
       "20244          0              0              0  \n",
       "19392         -2              1              0  \n",
       "18377          4              0              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting data\n",
    "\n",
    "#Defining variables\n",
    "X = train.drop(columns = ['default payment next month'])\n",
    "Y = train['default payment next month']\n",
    "\n",
    "#splitting data\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441dd046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-creating features from exam 1 for train dataset\n",
    "\n",
    "#creating features\n",
    "#1\n",
    "#total payment amount\n",
    "train['Total_Payment_Amount'] = np.sum(train[['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']], axis = 1)\n",
    "#2\n",
    "#total payment\n",
    "train['Total_Payment'] = np.sum(train[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']], axis = 1)\n",
    "#3\n",
    "#total bill amount\n",
    "train['Total_Bill_Amount'] = np.sum(train[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']], axis = 1)\n",
    "\n",
    "#top 2 features from strong heredity\n",
    "#4\n",
    "train['Heredity1']= train['PAY_0']*train['PAY_2']\n",
    "#5\n",
    "train['Heredity2']= train['PAY_0']*train['PAY_3']\n",
    "\n",
    "#choosing 2 features from decision tree\n",
    "#6\n",
    "train['DecisionTree1'] = np.where((train['PAY_0'] <= 1.5) & (train['PAY_2'] <= 0.5) & (train['PAY_AMT3'] <= 395.0), 1, 0)\n",
    "#7\n",
    "train['DecisionTree2'] = np.where((train['PAY_0'] <= 1.5) & (train['PAY_2'] <= 0.5) & (train['PAY_AMT3'] >= 395.0), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94472875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-creating features from exam 1 on test dataset\n",
    "\n",
    "#total payment amount\n",
    "test['Total_Payment_Amount'] = np.sum(test[['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']], axis = 1)\n",
    "#2\n",
    "#total payment\n",
    "test['Total_Payment'] = np.sum(test[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']], axis = 1)\n",
    "#3\n",
    "#total bill amount\n",
    "test['Total_Bill_Amount'] = np.sum(test[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']], axis = 1)\n",
    "\n",
    "#top 2 features from strong heredity\n",
    "#4\n",
    "test['Heredity1']= test['PAY_0']*test['PAY_2']\n",
    "#5\n",
    "test['Heredity2']= test['PAY_0']*test['PAY_3']\n",
    "\n",
    "#choosing 2 features from decision tree\n",
    "#6\n",
    "test['DecisionTree1'] = np.where((test['PAY_0'] <= 1.5) & (test['PAY_2'] <= 0.5) & (test['PAY_AMT3'] <= 395.0), 1, 0)\n",
    "#7\n",
    "test['DecisionTree2'] = np.where((test['PAY_0'] <= 1.5) & (test['PAY_2'] <= 0.5) & (test['PAY_AMT3'] <= 395.0), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d63a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using top 7 variables from exam 1 to create variables for the models\n",
    "# Defining variables\n",
    "X_training = X_train[['PAY_0','Total_Payment', 'PAY_2', 'DecisionTree2','PAY_3', 'PAY_4', 'Heredity1' ]]\n",
    "X_validation = X_validation[['PAY_0','Total_Payment', 'PAY_2', 'DecisionTree2','PAY_3', 'PAY_4', 'Heredity1' ]]\n",
    "test = test[['PAY_0','Total_Payment', 'PAY_2', 'DecisionTree2','PAY_3', 'PAY_4', 'Heredity1' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8ece8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cutoff Value for Random Forrest Model is 0.234\n",
      "F1 Score for Random Forrest Model is 0.536\n"
     ]
    }
   ],
   "source": [
    "############ MODEL 1 RANDOM FORREST  #####################\n",
    "\n",
    "\n",
    "#Building random forest model  \n",
    "RF = RandomForestClassifier().fit(X_training, Y_train)\n",
    "\n",
    "#Predicting on validation\n",
    "RF_preds = RF.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "# using precision recall cutoff for labels\n",
    "RF_labels = prc.precision_recall_cutoff(Y_validation, RF_preds)\n",
    "\n",
    "#Finding optimal cutoff\n",
    "RF_cutoff = prc.precision_recall_cutoff2(Y_validation, RF_preds)\n",
    "\n",
    "#Printing optimal cutoff \n",
    "print('Optimal Cutoff Value for Random Forrest Model is',round(RF_cutoff,3))\n",
    "\n",
    "#Printing the F1 score\n",
    "print('F1 Score for Random Forrest Model is',round(f1_score(Y_validation, RF_labels),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70bc461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest Parameters are {'max_depth': 7, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "F1 Score for Random Forrest Model is 0.47\n"
     ]
    }
   ],
   "source": [
    "################## Finding parameters for RF model ############################\n",
    "\n",
    "\n",
    "# Setting parameters\n",
    "rf_param_grid = {'n_estimators': [100, 300, 500], 'max_depth': [3, 5, 7], 'min_samples_split': [5, 10, 15], 'min_samples_leaf': [5, 10, 15]}\n",
    "\n",
    "#Running GridSearchCV with 3 folds\n",
    "RandomForrest_GridSearch = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv = 3, scoring = 'f1', n_jobs = -1).fit(X_validation, Y_validation)\n",
    "\n",
    "# Printing labels\n",
    "print('Random Forrest Parameters are', RandomForrest_GridSearch.best_params_)\n",
    "print('F1 Score for Random Forrest Model is',round(RandomForrest_GridSearch.best_score_, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef9e976d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cutoff Value for Random Forrest Model is 0.292\n",
      "F1 Score for Random Forrest Model is 0.542\n"
     ]
    }
   ],
   "source": [
    "# Building new Random Forest model with the best parameters\n",
    "RF = RandomForestClassifier(max_depth = 7, min_samples_leaf = 10, min_samples_split = 5, n_estimators = 100).fit(X_training, Y_train)\n",
    "\n",
    "#Predicting on validation\n",
    "RF_preds = RF.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "# using precision recall cutoff for labels\n",
    "RF_labels = prc.precision_recall_cutoff(Y_validation, RF_preds)\n",
    "\n",
    "#Finding optimal cutoff\n",
    "RF_cutoff = prc.precision_recall_cutoff2(Y_validation, RF_preds)\n",
    "\n",
    "#Printing optimal cutoff \n",
    "print('Optimal Cutoff Value for Random Forrest Model is',round(RF_cutoff,3))\n",
    "\n",
    "#Printing the F1 score\n",
    "print('F1 Score for Random Forrest Model is',round(f1_score(Y_validation, RF_labels),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d85fe363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Model to predict likelyhood of default payment on next month on test dataset\n",
    "RF_test_preds = RF.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c7e5b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cutoff Value for Ada Boost Model is 0.495\n",
      "F1 Score for Ada Boost Model is 0.534\n"
     ]
    }
   ],
   "source": [
    "############ MODEL 2 ADA BOOST  #####################\n",
    "\n",
    "\n",
    "#Building Ada Boost model  \n",
    "ADA = AdaBoostClassifier().fit(X_training, Y_train)\n",
    "\n",
    "#Predicting on validation\n",
    "ADA_preds = ADA.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "# using precision recall cutoff for labels\n",
    "ADA_labels = prc.precision_recall_cutoff(Y_validation, ADA_preds)\n",
    "\n",
    "#Finding optimal cutoff\n",
    "ADA_cutoff = prc.precision_recall_cutoff2(Y_validation, ADA_preds)\n",
    "\n",
    "#Printing optimal cutoff \n",
    "print('Optimal Cutoff Value for Ada Boost Model is',round(ADA_cutoff,3))\n",
    "\n",
    "#Printing the F1 score\n",
    "print('F1 Score for Ada Boost Model is',round(f1_score(Y_validation, ADA_labels),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afcc72ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Parameters are {'base_estimator__max_depth': 3, 'base_estimator__min_samples_leaf': 15, 'base_estimator__min_samples_split': 15, 'learning_rate': 1, 'n_estimators': 500}\n",
      "F1 Score for AdaBoost Model is 0.489\n"
     ]
    }
   ],
   "source": [
    "################## Finding parameters for ADA model ############################\n",
    "\n",
    "\n",
    "# Setting parameters\n",
    "ada_param_grid = {'n_estimators': [100, 300, 500], 'base_estimator__min_samples_split': [5, 10, 15], 'base_estimator__min_samples_leaf': [5, 10, 15], 'base_estimator__max_depth': [3, 5, 7], 'learning_rate': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "#Running GridSearchCV with 3 folds\n",
    "AdaBoost_GridSearch = GridSearchCV(AdaBoostClassifier(base_estimator = DecisionTreeClassifier()), ada_param_grid, cv = 3, scoring = 'f1', n_jobs = -1).fit(X_validation, Y_validation)\n",
    "\n",
    "# Printing labels\n",
    "print('AdaBoost Parameters are', AdaBoost_GridSearch.best_params_)\n",
    "print('F1 Score for AdaBoost Model is',round(AdaBoost_GridSearch.best_score_, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40aee832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cutoff Value for Ada Boost Model is 0.5\n",
      "F1 Score for Ada Boost Model is 0.538\n"
     ]
    }
   ],
   "source": [
    "#Building Ada Boost model  \n",
    "ADA = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(min_samples_split = 15, min_samples_leaf = 15, max_depth = 3), n_estimators = 500, learning_rate = 1).fit(X_training, Y_train)\n",
    "\n",
    "#Predicting on validation\n",
    "ADA_preds = ADA.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "# using precision recall cutoff for labels\n",
    "ADA_labels = prc.precision_recall_cutoff(Y_validation, ADA_preds)\n",
    "\n",
    "#Finding optimal cutoff\n",
    "ADA_cutoff = prc.precision_recall_cutoff2(Y_validation, ADA_preds)\n",
    "\n",
    "#Printing optimal cutoff \n",
    "print('Optimal Cutoff Value for Ada Boost Model is',round(ADA_cutoff,3))\n",
    "\n",
    "#Printing the F1 score\n",
    "print('F1 Score for Ada Boost Model is',round(f1_score(Y_validation, ADA_labels),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "439aa88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Model to predict likelyhood of default payment on next month on test dataset\n",
    "ada_test_preds = ADA.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9ed55dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cutoff Value for XGBoost Model is 0.224\n",
      "F1 Score for XGBoost Model is 0.543\n"
     ]
    }
   ],
   "source": [
    "############ MODEL 3 XGBoost  #####################\n",
    "\n",
    "\n",
    "#Building XGBoost model  \n",
    "XGB = XGBClassifier(eval_metric = 'error', use_label_encoder = False).fit(X_training, Y_train)\n",
    "\n",
    "#Predicting on validation\n",
    "XGB_preds = XGB.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "# using precision recall cutoff for labels\n",
    "XGB_labels = prc.precision_recall_cutoff(Y_validation, XGB_preds)\n",
    "\n",
    "#Finding optimal cutoff\n",
    "XGB_cutoff = prc.precision_recall_cutoff2(Y_validation, XGB_preds)\n",
    "\n",
    "#Printing optimal cutoff \n",
    "print('Optimal Cutoff Value for XGBoost Model is',round(XGB_cutoff,3))\n",
    "\n",
    "#Printing the F1 score\n",
    "print('F1 Score for XGBoost Model is',round(f1_score(Y_validation, XGB_labels),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Finding parameters for XGB model ############################\n",
    "\n",
    "\n",
    "# Setting parameters\n",
    "xgb_param_grid = {'n_estimators': [300, 500], 'max_depth': [5, 7], 'min_child_weight': [5, 7], 'learning_rate' : [0.01, 0.001], 'gamma': [0.1, 0.01], 'subsample': [0.8, 1], 'colsample_bytree': [0.8, 1], 'early_stopping_rounds': [100]}\n",
    "\n",
    "#Running GridSearchCV with 3 folds\n",
    "XGB_GridSearch = GridSearchCV(XGBClassifier(eval_metric = 'error', use_label_encoder = False), xgb_param_grid, cv = 3, scoring = 'f1', n_jobs = -1).fit(X_validation, Y_validation)\n",
    "\n",
    "# Printing labels\n",
    "print('XGBoost Parameters are', XGB_GridSearch.best_params_)\n",
    "print('F1 Score for XGBoost Model is',round(XGB_GridSearch.best_score_, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a90ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building XGB Boost model  \n",
    "XGB =  XGBClassifier(n_estimators = 500, max_depth = 7, min_child_weight = 5, learning_rate = 0.01, gamma = 0.1, subsample = 1, colsample_bytree = 1, early_stopping_rounds = 100, eval_metric = 'error', use_label_encoder = False).fit(X_training, Y_train)\n",
    "\n",
    "#Predicting on validation\n",
    "XGB_preds = XGB.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "# using precision recall cutoff for labels\n",
    "XGB_labels = prc.precision_recall_cutoff(Y_validation, XGB_preds)\n",
    "\n",
    "#Finding optimal cutoff\n",
    "XGB_cutoff = prc.precision_recall_cutoff2(Y_validation, XGB_preds)\n",
    "\n",
    "#Printing optimal cutoff \n",
    "print('Optimal Cutoff Value for XGBoost Model is',round(XGB_cutoff,3))\n",
    "\n",
    "#Printing the F1 score\n",
    "print('F1 Score for XGBoost Model is',round(f1_score(Y_validation, XGB_labels),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using Model to predict likelyhood of default payment on next month on test dataset\n",
    "xgb_test_preds = XGB.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "###### Model crashed, here is the rest of my code un run, was waiting on XGBoost #############################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a25320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building metalearner\n",
    "\n",
    "#creating dataframe\n",
    "METADATA = pd.DataFrame({'RF': RF_preds, 'ADA': ADA_preds, 'XGB': XGB_preds, 'Y_validation': Y_validation})\n",
    "\n",
    "#Building metalearner\n",
    "METADATA_test = pd.DataFrame({'RF': rf_test_preds, 'ADA': ada_test_preds, 'XGB': xgb_test_preds})\n",
    "\n",
    "#Defining variable\n",
    "X_METADATA = METADATA[['RF', 'ADA', 'XGB']]\n",
    "Y_METADATA = METADATA['Y_validation']\n",
    "\n",
    "## Defining the parameter dictionary\n",
    "meta_param_grid = {'n_estimators': [100, 300, 500], 'max_depth': [3, 5, 7], 'min_samples_split': [5, 10, 15], \n",
    "                  'min_samples_leaf': [5, 10, 15]}\n",
    "\n",
    "## Running GridSearchCV with 3 folds\n",
    "meta_GridSearch = GridSearchCV(RandomForestClassifier(), meta_param_grid, cv = 3, scoring = 'f1', n_jobs = -1).fit(X_METADATA, Y_METADATA)\n",
    "\n",
    "# Printing labels\n",
    "print('Metalearner Parameters are', meta_GridSearch.best_params_)\n",
    "print('F1 Score for Metalearner is',round(meta_GridSearch.best_score_, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef0d2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
